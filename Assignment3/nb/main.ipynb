{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from connect_four import Game, GameType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_init = np.array(\n",
    "    [\n",
    "        [2, 2, 2, 1, 0, 1, 0],\n",
    "        [2, 1, 1, 1, 0, 2, 0],\n",
    "        [1, 2, 2, 2, 0, 1, 0],\n",
    "        [2, 1, 1, 1, 0, 2, 0],\n",
    "        [1, 1, 1, 2, 0, 2, 0],\n",
    "        [2, 2, 1, 2, 0, 1, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game(game_state=game_init, game_type=GameType.MCTS_VS_RANDOM, mcts_maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the MCTS for several \"epochs\"\n",
    "The tree nodes store the state of the game when they are created. This states are the result from (first) the action chosen to create the node plus (second) the random action of player 2. This node states are frozen and kept untouched. This means we have a limited view of all the possible outcomes. \n",
    "\n",
    "We run the MCTS for sevral \"epochs\" before choosing an action to take. Each epoch consists of a single independent run of the tree search algorithm. This means that we will have as many action-value pairs as epochs (for the root node). We take the average of the q-values to select an action. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from connect_four.utils import display_circles\n",
    "\n",
    "\n",
    "class QValuesDict(dict):\n",
    "    \"\"\"This keeps a running average of q-values returned by mcts\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        self._updates = 0\n",
    "        self._cache = []\n",
    "        return super().__init__(*args, **kwargs)\n",
    "\n",
    "    def update(self, new: Dict[int, float]) -> None:\n",
    "        self._cache.append(new)\n",
    "        for key in new:\n",
    "            # Update the running average of each action\n",
    "            # This is: \\bar{x}_{N+1} = 1 / (N + 1) * (N * \\bar{x}_N + x_{N + 1}) \n",
    "            # Where \\bar{x}_N is the mean value of x given N updates\n",
    "            self[key] = 1 / (self._updates + 1) * (self._updates * self.get(key, 0.0) + new[key])\n",
    "\n",
    "        self._updates += 1\n",
    "\n",
    "\n",
    "def select_best_action_dope(self, epochs: int = 25):\n",
    "    print(\"Running tree search to choose action ...\")\n",
    "    qvalues = QValuesDict()\n",
    "    for e in range(epochs):\n",
    "        print(f\"\\tRunning epoch {e} to find best action ...\")\n",
    "        epoch_qvalues = self.mcts.run(game_state=self.game_board.snapshot())\n",
    "        qvalues.update(epoch_qvalues)\n",
    "        print(qvalues)\n",
    "    print(f\"Qvalues: {qvalues}\")\n",
    "    print(f\"Choosing {int(max(qvalues, key=qvalues.get))}\")\n",
    "    return int(max(qvalues, key=qvalues.get))\n",
    "\n",
    "def play(self):\n",
    "\n",
    "    self.init_gameboard()\n",
    "\n",
    "    while not self.game_board.is_finished:\n",
    "        self.game_board.play(\n",
    "            first_action=self.first_move(), second_action=self.second_move()\n",
    "        )\n",
    "\n",
    "    winner = self.game_board.check_winner()\n",
    "    print(f\"The winner of the game is: {winner if winner else 'DRAW'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Game.select_best_action = select_best_action_dope\n",
    "Game.play = play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tree search to choose action ...\n",
      "\tRunning epoch 0 to find best action ...\n",
      "{np.int64(4): 0.7142857142857143, np.int64(6): -0.247557003257329}\n",
      "\tRunning epoch 1 to find best action ...\n",
      "{np.int64(4): 0.7093912511471399, np.int64(6): 0.3086792844876582}\n",
      "\tRunning epoch 2 to find best action ...\n",
      "{np.int64(4): 0.7098752919294185, np.int64(6): 0.44615803560797396}\n",
      "\tRunning epoch 3 to find best action ...\n",
      "{np.int64(4): 0.7085428325834274, np.int64(6): 0.4770973402653025}\n",
      "\tRunning epoch 4 to find best action ...\n",
      "{np.int64(4): 0.7089218081542841, np.int64(6): 0.4329093993058381}\n",
      "\tRunning epoch 5 to find best action ...\n",
      "{np.int64(4): 0.7081999765224489, np.int64(6): 0.4783263030287461}\n",
      "\tRunning epoch 6 to find best action ...\n",
      "{np.int64(4): 0.7088649452949395, np.int64(6): 0.4431254310962462}\n",
      "\tRunning epoch 7 to find best action ...\n",
      "{np.int64(4): 0.7282334808295701, np.int64(6): 0.48752899089234303}\n",
      "\tRunning epoch 8 to find best action ...\n",
      "{np.int64(4): 0.7266837289913638, np.int64(6): 0.4767257953428473}\n",
      "\tRunning epoch 9 to find best action ...\n",
      "{np.int64(4): 0.7403952844076396, np.int64(6): 0.4876505008764359}\n",
      "\tRunning epoch 10 to find best action ...\n",
      "{np.int64(4): 0.7522455584905567, np.int64(6): 0.4836981605496284}\n",
      "\tRunning epoch 11 to find best action ...\n",
      "{np.int64(4): 0.7486002639739684, np.int64(6): 0.5046548026382134}\n",
      "\tRunning epoch 12 to find best action ...\n",
      "{np.int64(4): 0.7212043075289462, np.int64(6): 0.4849841386054867}\n",
      "\tRunning epoch 13 to find best action ...\n",
      "{np.int64(4): 0.7204143518151809, np.int64(6): 0.48318680217448257}\n",
      "\tRunning epoch 14 to find best action ...\n",
      "{np.int64(4): 0.6984184743925814, np.int64(6): 0.5024686015697469}\n",
      "\tRunning epoch 15 to find best action ...\n",
      "{np.int64(4): 0.6991608625004622, np.int64(6): 0.4933125575313567}\n",
      "\tRunning epoch 16 to find best action ...\n",
      "{np.int64(4): 0.7046202707604178, np.int64(6): 0.49721973139859077}\n",
      "\tRunning epoch 17 to find best action ...\n",
      "{np.int64(4): 0.705087519424045, np.int64(6): 0.45855540352383556}\n",
      "\tRunning epoch 18 to find best action ...\n",
      "{np.int64(4): 0.7039887303130842, np.int64(6): 0.48163453089255004}\n",
      "\tRunning epoch 19 to find best action ...\n",
      "{np.int64(4): 0.7042629780079563, np.int64(6): 0.49898137577649404}\n",
      "\tRunning epoch 20 to find best action ...\n",
      "{np.int64(4): 0.7034647409599584, np.int64(6): 0.5162651340017782}\n",
      "\tRunning epoch 21 to find best action ...\n",
      "{np.int64(4): 0.7027630246186082, np.int64(6): 0.5036316841984809}\n",
      "\tRunning epoch 22 to find best action ...\n",
      "{np.int64(4): 0.7028690805977438, np.int64(6): 0.508400115898791}\n",
      "\tRunning epoch 23 to find best action ...\n",
      "{np.int64(4): 0.7033697312402032, np.int64(6): 0.5215539351614529}\n",
      "\tRunning epoch 24 to find best action ...\n",
      "{np.int64(4): 0.7035426342982875, np.int64(6): 0.5251917777549948}\n",
      "Qvalues: {np.int64(4): 0.7035426342982875, np.int64(6): 0.5251917777549948}\n",
      "Choosing 4\n",
      "Running tree search to choose action ...\n",
      "\tRunning epoch 0 to find best action ...\n",
      "{np.int64(4): 0.9961977186311787, np.int64(6): 0.8734177215189873}\n",
      "\tRunning epoch 1 to find best action ...\n",
      "{np.int64(4): 0.8544818380389936, np.int64(6): 0.6385437231448148}\n",
      "\tRunning epoch 2 to find best action ...\n",
      "{np.int64(4): 0.9029878920259957, np.int64(6): 0.5574376368268703}\n",
      "\tRunning epoch 3 to find best action ...\n",
      "{np.int64(4): 0.8540946264343264, np.int64(6): 0.5962219401950031}\n",
      "\tRunning epoch 4 to find best action ...\n",
      "{np.int64(4): 0.48327570114746116, np.int64(6): 0.6192052143347051}\n",
      "\tRunning epoch 5 to find best action ...\n",
      "{np.int64(4): 0.5475077371976185, np.int64(6): 0.6341342524880572}\n",
      "\tRunning epoch 6 to find best action ...\n",
      "{np.int64(4): 0.5939579427450962, np.int64(6): 0.6447085744808732}\n",
      "\tRunning epoch 7 to find best action ...\n",
      "{np.int64(4): 0.3947131999019592, np.int64(6): 0.6730485740993355}\n",
      "\tRunning epoch 8 to find best action ...\n",
      "{np.int64(4): 0.23974506657951927, np.int64(6): 0.6775916692347258}\n",
      "\tRunning epoch 9 to find best action ...\n",
      "{np.int64(4): 0.11577055992156736, np.int64(6): 0.6809463334006045}\n",
      "\tRunning epoch 10 to find best action ...\n",
      "{np.int64(4): 0.01433687265597032, np.int64(6): 0.6839454331203539}\n",
      "\tRunning epoch 11 to find best action ...\n",
      "{np.int64(4): 0.08557532595433004, np.int64(6): 0.7099664569129227}\n",
      "\tRunning epoch 12 to find best action ...\n",
      "{np.int64(4): 0.0020695316501508055, np.int64(6): 0.7102718394825325}\n",
      "\tRunning epoch 13 to find best action ...\n",
      "{np.int64(4): -0.0695068634677171, np.int64(6): 0.6882950939907374}\n",
      "\tRunning epoch 14 to find best action ...\n",
      "{np.int64(4): -0.13153973923653597, np.int64(6): 0.7005039924865931}\n",
      "\tRunning epoch 15 to find best action ...\n",
      "{np.int64(4): -0.18581850553425247, np.int64(6): 0.7111867786704668}\n",
      "\tRunning epoch 16 to find best action ...\n",
      "{np.int64(4): -0.13290089234236024, np.int64(6): 0.6926648131048686}\n",
      "\tRunning epoch 17 to find best action ...\n",
      "{np.int64(4): -0.1810730649900069, np.int64(6): 0.7025961330117411}\n",
      "\tRunning epoch 18 to find best action ...\n",
      "{np.int64(4): -0.1340389641853012, np.int64(6): 0.7028497486247715}\n",
      "\tRunning epoch 19 to find best action ...\n",
      "{np.int64(4): -0.17733701597603616, np.int64(6): 0.7032641767382086}\n",
      "\tRunning epoch 20 to find best action ...\n",
      "{np.int64(4): -0.21651144378670106, np.int64(6): 0.70377237928962}\n",
      "\tRunning epoch 21 to find best action ...\n",
      "{np.int64(4): -0.25212455997821465, np.int64(6): 0.690082607621792}\n",
      "\tRunning epoch 22 to find best action ...\n",
      "{np.int64(4): -0.2846408834574227, np.int64(6): 0.6911197303477075}\n",
      "\tRunning epoch 23 to find best action ...\n",
      "{np.int64(4): -0.3144475133133634, np.int64(6): 0.6920704261797966}\n",
      "\tRunning epoch 24 to find best action ...\n",
      "{np.int64(4): -0.2669632457396304, np.int64(6): 0.6927137893901155}\n",
      "Qvalues: {np.int64(4): -0.2669632457396304, np.int64(6): 0.6927137893901155}\n",
      "Choosing 6\n",
      "Running tree search to choose action ...\n",
      "\tRunning epoch 0 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 1 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 2 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 3 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 4 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 5 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 6 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 7 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 8 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 9 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 10 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 11 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 12 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 13 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 14 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 15 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 16 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 17 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 18 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 19 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 20 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 21 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 22 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 23 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "\tRunning epoch 24 to find best action ...\n",
      "{np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "Qvalues: {np.int64(6): -1.0, np.int64(4): 1.0}\n",
      "Choosing 4\n",
      "The winner of the game is: 1\n"
     ]
    }
   ],
   "source": [
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
